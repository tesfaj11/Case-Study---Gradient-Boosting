# Case-Study---Gradient-Boosting

# Gradient Boosting Case Study

## Overview

This case study demonstrates how gradient boosting can be used to improve model predictions by learning from residual errors. The notebook covers both regression and classification tasks using Pythonâ€™s `scikit-learn` library.

The first part uses synthetic data to show how gradient boosting works for a regression problem. The second part focuses on a real-world classification problem using the Titanic dataset to predict survival.

## Objectives

- Understand how gradient boosting improves prediction performance
- Apply gradient boosting to a regression problem
- Use gradient boosting to classify survival on the Titanic dataset
- Evaluate model performance using standard metrics

## What I Did

- Cleaned and prepared both datasets
- Built and trained a `GradientBoostingRegressor` and `GradientBoostingClassifier`
- Evaluated models using metrics like Mean Squared Error (for regression) and Accuracy, Confusion Matrix, and Classification Report (for classification)
- Interpreted the results and identified model strengths

## Tools Used

- Python
- Pandas
- scikit-learn
- Jupyter Notebook
